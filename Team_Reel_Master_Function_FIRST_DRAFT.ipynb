{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LJxUvLu_Pb-i"
   },
   "source": [
    "## **Team Reel Master Function -- Draft Working Version:**\n",
    "\n",
    "- Python module that goes in parent directory (as .py file)\n",
    "- runs when any new video or feedback is added (triggered by message in SQS queue for new video --> AWS Lambda function --> calls this function via API endpoint)\n",
    "- calls all other TeamReel functions (ML ones by us) + gets human feedback from DB\n",
    "- Adds video analysis (all of the above) to the video_feedback table in the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yUtNCmc_OE9U"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'textblob'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-75fa1d826947>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Import functions we need from audio_analysis package:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0maudio_analysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_functions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_audio_from_video\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0maudio_analysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_functions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0manalyse_audio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents - LSDS Lambda School/Labs24-TeamReel/video-journal-for-teams-ds/audio_analysis/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \"\"\"\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0maudio_functions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_audio_from_video\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_transcripts_from_audio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0maudio_functions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_sentiment_analysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents - LSDS Lambda School/Labs24-TeamReel/video-journal-for-teams-ds/audio_analysis/audio_functions.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import external modules, packages, libraries we will use:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtextblob\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msimple_preprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSTOPWORDS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'textblob'"
     ]
    }
   ],
   "source": [
    "# Import modules/libraries we will use:\n",
    "\n",
    "# Import libraries we will use:\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import os\n",
    "import psycopg2\n",
    "\n",
    "# Import functions we need for TeamReel data infra, video and DB:\n",
    "from data_infra.data_pipelines import get_next_video\n",
    "from data_infra.postgresql_db_functions import get_feedback_for_user\n",
    "from data_infra.postgresql_db_functions import get_feedback_for_video, get_video_info\n",
    "\n",
    "# Import functions we need from audio_analysis package:\n",
    "from audio_analysis.audio_functions import get_audio_from_video\n",
    "from audio_analysis.audio_functions import analyse_audio, remove_files\n",
    "\n",
    "# Import functions we need from facial_analysis package:\n",
    "# To add\n",
    "\n",
    "# Import functions we need from audio_analysis.background_noise module:\n",
    "# To add\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# SETUP:\n",
    "\n",
    "# Get access info from .env file:\n",
    "load_dotenv()\n",
    "\n",
    "# PostgreSQL DB info:\n",
    "PG_DB_HOST = os.getenv(\"PG_DB_HOST\")\n",
    "PG_DB_PORT = os.getenv(\"PG_DB_PORT\")\n",
    "PG_DB_NAME = os.getenv(\"PG_DB_NAME\")\n",
    "PG_DB_USER = os.getenv(\"PG_DB_USER\")\n",
    "PG_DB_PW = os.getenv(\"PG_DB_PW\")\n",
    "PG_DB_URI = os.getenv(\"PG_DB_URI\")\n",
    "\n",
    "# Open a connection to our PostgreSQL DB:\n",
    "pg_conn = psycopg2.connect(\n",
    "    host = PG_DB_HOST,\n",
    "    port = PG_DB_PORT,\n",
    "    database = PG_DB_NAME,\n",
    "    user = PG_DB_USER,\n",
    "    password = PG_DB_PW\n",
    ")\n",
    "\n",
    "# Instantiate a cursor using this connection:\n",
    "pg_cursor = pg_conn.cursor()\n",
    "\n",
    "# ----------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET BASE MATERIALS: VIDEO, AUDIO, TRANSCRIPT:\n",
    "\n",
    "# Get next video in line for analysis (recently uploaded by a user):\n",
    "# (1) video_feedback dict = info about that video from our DB (video_id, etc.)\n",
    "# (2) download .MP4 video file to project directory\n",
    "video_feedback = get_next_video()\n",
    "\n",
    "try:\n",
    "    video_s3_key = video_info['video']['s3_key']\n",
    "    video_filename = video_info['video']['s3_filename']\n",
    "except KeyError:\n",
    "    \"KeyError: There is no information about this video in our database.\"\n",
    "\n",
    "# Get audio from the video file:\n",
    "get_audio_from_video(video_file=video_s3_filename)\n",
    "audio_filename = 'audio.wav'\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# SENTIMENT: AUDIO:\n",
    "\n",
    "# Directory paths \n",
    "dirname = r\"audio_chunks/\"\n",
    "path = r\"text_chunks/\"\n",
    "\n",
    "# analyse_audio() function is the one function that does both: audio-sentiment analysis,\n",
    "# and gets number of words per minute\n",
    "data = analyse_audio() \n",
    "\n",
    "# Get the filename of the transcript\n",
    "transcript_filename = 'outputfile.txt'\n",
    "# Get the text in the transcript as a string\n",
    "transcript_string = open(transcript_filename).read().replace(\"\\n\", \" \")\n",
    "\n",
    "\n",
    "# Add audio sentiment score to our video_feedback dict: \n",
    "video_feedback['sentiment_audio'] = data[0]['positive'] + data[0]['neutral'] # need to do some analysis and output 1 audio sentiment score\n",
    "video_feedback['sentiment_audio_details'] = json.dumps(data[0])\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# SPEED OF SPEECH: \n",
    "\n",
    "video_feedback['speaking_speed'] = round(data[2])\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# SENTIMENT: VISUAL:\n",
    "\n",
    "# [To add:] Facial centering: Call Chris Huskey's master function and get results\n",
    "visual_sentiment_results = [To add]\n",
    "\n",
    "# Add visual sentiment score to our video_feedback dict: \n",
    "video_feedback['sentiment_visual'] = ?? # need to do some analysis and output 1 visual sentiment score\n",
    "video_feedback['sentiment_visual_details'] = visual_sentiment_results\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# BACKGROUND NOISE:\n",
    "\n",
    "# [To add:] Background noise: Call Chris Howell's master function and get results\n",
    "# add to our video_feedback dict: video_feedback['']\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# ADD VIDEO ANALYSIS RESULTS TO DB:\n",
    "\n",
    "# [To add:] Add all of the above info for this video to the videos_feedback table in our DB\n",
    "\n",
    "# pseudocode:\n",
    "# if [video is in the video_feedback table already]:\n",
    "#   Update info in the videos_feedback table\n",
    "# else:\n",
    "#   Add info to the video feedback table\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "# To add: Make Plotly visualizations so Web can display them super easily?\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# REMOVE STORED FILES:\n",
    "\n",
    "# To add: Remove local files (video, audio, transcript, audio chunks, (text chunks?))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DJYR4JnpXYiE"
   },
   "outputs": [],
   "source": [
    "# {'video': {'video_id': 134,\n",
    "#   'title': 'Kyla Oyamot',\n",
    "#   's3_key': 'videos/ALPACAVID-i7swK-Wzc.webm',\n",
    "#   's3_filename': 'ALPACAVID-i7swK-Wzc.webm',\n",
    "#   'created_at': datetime.datetime(2020, 5, 5, 16, 22, 56, 852000, tzinfo=psycopg2.tz.FixedOffsetTimezone(offset=0, name=None)),\n",
    "#   'updated_at': datetime.datetime(2020, 5, 5, 16, 22, 56, 852000, tzinfo=psycopg2.tz.FixedOffsetTimezone(offset=0, name=None))},\n",
    "#  'prompt': {'prompt_id': 65,\n",
    "#   'question': 'What is your first impression of Labs'},\n",
    "#  'user': {'user_id': 185,\n",
    "#   'first_name': 'Kyla',\n",
    "#   'last_name': 'O',\n",
    "#   'name': 'Kyla O',\n",
    "#   'username': 'kylao'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gYLbu1nQYN8Z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mG0K1wwEXYk2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eWFIkROpaJWn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Close the cursor:\n",
    "# pg_cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Close the connection:\n",
    "# pg_conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "svEMIPaWaJZv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "javZT17PaJdt"
   },
   "outputs": [],
   "source": [
    "# id SERIAL PRIMARY KEY, \n",
    "# FOREIGN KEY (video_id) NOT NULL REFERENCES videos (id), \n",
    "# FOREIGN KEY (video_url) NOT NULL REFERENCES videos (video_url), \n",
    "\n",
    "# overall_performance NUMERIC, \n",
    "\n",
    "# sentiment_visual NUMERIC, \n",
    "# sentiment_visual_details JSONB, \n",
    "# sentiment_audio NUMERIC, \n",
    "# sentiment_audio_details JSONB, \n",
    "# sentiment_smile_frequency NUMERIC, \n",
    "\n",
    "# speaking_vocabulary NUMERIC, \n",
    "# speaking_speed NUMERIC, \n",
    "\n",
    "# background_noise NUMERIC, \n",
    "\n",
    "# appearance_facial_centering NUMERIC, \n",
    "\n",
    "# human_overall_performance NUMERIC, \n",
    "# human_delivery_and_presentation NUMERIC, \n",
    "# human_response_quality NUMERIC, \n",
    "# human_audio_quality NUMERIC, \n",
    "# human_visual_environment NUMERIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_H5aGuJDbB-Z"
   },
   "outputs": [],
   "source": [
    "# - human score: overall rating\n",
    "# - human score: delivery and presentation\n",
    "# - human score: response quality\n",
    "# - human score: audio quality\n",
    "# - human score: visual environment\n",
    "# - ML score: attitude\n",
    "# - ML score: speaking speed\n",
    "# - ML score: background noise\n",
    "# - ML score: facial centering and posture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Team Reel Master Function -- FIRST DRAFT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
